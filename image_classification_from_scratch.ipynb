{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zoghbii/Perros-Y-Gatos/blob/main/image_classification_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGs4xQ0pUvGq"
      },
      "source": [
        "# Clasificación de imágenes desde cero (gatos y Perros)\n",
        "\n",
        "**Descripción:** Entrenamiento de un clasificador de imágenes desde cero para perros y gatos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfuZ083JUvGt"
      },
      "source": [
        "## Introduccion\n",
        "Utilizamos la utilidad `image_dataset_from_directory` para generar los conjuntos de datos y las capas de preprocesamiento de imágenes de Keras para la estandarización y el aumento de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE3NZIwTUvGv"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k3h_n9zTeYdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0sSi2x5UvGw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers\n",
        "from tensorflow import data as tf_data\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjsSlrF1UvGx"
      },
      "source": [
        "## Cargamos los datos: el conjunto de datos Gatos vs. Perros\n",
        "\n",
        "###\n",
        "Descarga de datos sin procesar\n",
        "\n",
        "Primero, descargamos el archivo ZIP de 786M de los datos sin procesar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrY4BX4pUvGy"
      },
      "outputs": [],
      "source": [
        "!curl -O https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGhIu0MdUvGz"
      },
      "outputs": [],
      "source": [
        "!unzip -q kagglecatsanddogs_5340.zip\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlgcMjnMUvG2"
      },
      "source": [
        "Ahora tenemos una carpeta (PetImages) que contiene dos (subcarpetas): Gato y Perro. Cada subcarpeta contiene archivos de imagen para cada categoría."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljnl9hJsUvG3"
      },
      "outputs": [],
      "source": [
        "!ls PetImages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t336R5oUvG5"
      },
      "source": [
        "### Filtrar imágenes corruptas\n",
        "\n",
        "Al trabajar con una gran cantidad de datos de imágenes reales, es común encontrar imágenes corruptas. Filtraremos las imágenes corruptas que no incluyan la cadena \"JFIF\" en su encabezado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hG95NG9KUvG5"
      },
      "outputs": [],
      "source": [
        "num_skipped = 0\n",
        "for folder_name in (\"Cat\", \"Dog\"):\n",
        "    folder_path = os.path.join(\"PetImages\", folder_name)\n",
        "    for fname in os.listdir(folder_path):\n",
        "        fpath = os.path.join(folder_path, fname)\n",
        "        try:\n",
        "            fobj = open(fpath, \"rb\")\n",
        "            is_jfif = b\"JFIF\" in fobj.peek(10)\n",
        "        finally:\n",
        "            fobj.close()\n",
        "\n",
        "        if not is_jfif:\n",
        "            num_skipped += 1\n",
        "            # Delete corrupted image\n",
        "            os.remove(fpath)\n",
        "\n",
        "print(f\"Deleted {num_skipped} images.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7ZaVilpUvG7"
      },
      "source": [
        "\n",
        "## Generamos un `Conjunto de datos`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyKPBZ5dUvG7"
      },
      "outputs": [],
      "source": [
        "image_size = (180, 180)\n",
        "batch_size = 128\n",
        "\n",
        "train_ds, val_ds = keras.utils.image_dataset_from_directory(\n",
        "    \"PetImages\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"both\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znbLnEeMUvG8"
      },
      "source": [
        "## vemos los datos\n",
        "\n",
        "Aquí están las primeras 9 imágenes en el conjunto de datos de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELgzChhqUvG9"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(np.array(images[i]).astype(\"uint8\"))\n",
        "        plt.title(int(labels[i]))\n",
        "        plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulNF0BHuUvG-"
      },
      "source": [
        "## aumento de datos de imágenes\n",
        "\n",
        "\n",
        "Cuando no se dispone de un conjunto grande de datos de imágenes, es recomendable introducir artificialmente diversidad de muestras aplicando transformaciones aleatorias pero realistas a las imágenes de entrenamiento, como volteos horizontales aleatorios o pequeñas rotaciones aleatorias. Esto ayuda a exponer el modelo a diferentes aspectos de los datos de entrenamiento y, al mismo tiempo, ralentiza el sobreajuste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjOPr1RhUvG-"
      },
      "outputs": [],
      "source": [
        "data_augmentation_layers = [\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "]\n",
        "\n",
        "\n",
        "def data_augmentation(images):\n",
        "    for layer in data_augmentation_layers:\n",
        "        images = layer(images)\n",
        "    return images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDYkYZTZUvG_"
      },
      "source": [
        "Visualicemos cómo se ven las muestras aumentadas aplicando `data_augmentation` repetidamente a las primeras imágenes del conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45kwOBVFUvG_"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        augmented_images = data_augmentation(images)\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(np.array(augmented_images[0]).astype(\"uint8\"))\n",
        "        plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80iuKrH-UvG_"
      },
      "source": [
        "## Estandarización de los datos\n",
        "\n",
        "Nuestras imágenes ya tienen un tamaño estándar (180x180), ya que nuestro conjunto de datos las genera como lotes contiguos de `float32`. Sin embargo, sus valores de canal RGB están en el rango `[0, 255]`. Esto no es ideal para una red neuronal; en general, se recomienda que los valores de entrada sean pequeños. Aquí, estandarizaremos los valores para que estén en el rango `[0, 1]` mediante una capa de `Reescalado` al inicio de nuestro modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFa5vv-vUvHA"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rexyrz4SUvHA"
      },
      "source": [
        "## Configurar el conjunto de datos para el rendimiento\n",
        "\n",
        "Apliquemos la ampliación de datos a nuestro conjunto de datos de entrenamiento y asegurémonos de usar la precarga en búfer para poder extraer datos del disco sin que la I/O se bloquee."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHqGsyr_UvHA"
      },
      "outputs": [],
      "source": [
        "# Apply `data_augmentation` to the training images.\n",
        "train_ds = train_ds.map(\n",
        "    lambda img, label: (data_augmentation(img), label),\n",
        "    num_parallel_calls=tf_data.AUTOTUNE,\n",
        ")\n",
        "# Prefetching samples in GPU memory helps maximize GPU utilization.\n",
        "train_ds = train_ds.prefetch(tf_data.AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(tf_data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR8LZGVhUvHB"
      },
      "source": [
        "## Construir un modelo\n",
        "\n",
        "Construiremos una versión reducida de la red Xception. No hemos intentado optimizar la arquitectura en detalle; si desea realizar una búsqueda sistemática de la mejor configuración del modelo, considere usar [KerasTuner](https://github.com/keras-team/keras-tuner).\n",
        "\n",
        "Tenga en cuenta que:\n",
        "\n",
        "- Iniciamos el modelo con el preprocesador `data_augmentation`, seguido de una capa `Rescaling`.\n",
        "- Incluimos una capa `Dropout` antes de la capa de clasificación final."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pG5qcJq-UvHB"
      },
      "outputs": [],
      "source": [
        "\n",
        "def make_model(input_shape, num_classes):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    # Entry block\n",
        "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
        "    x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    for size in [256, 512, 728]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    if num_classes == 2:\n",
        "        units = 1\n",
        "    else:\n",
        "        units = num_classes\n",
        "\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "    # We specify activation=None so as to return logits\n",
        "    outputs = layers.Dense(units, activation=None)(x)\n",
        "    return keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "model = make_model(input_shape=image_size + (3,), num_classes=2)\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nfbdb-GPUvHC"
      },
      "source": [
        "## Entrenando el Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3ZSY4ZJUvHC"
      },
      "outputs": [],
      "source": [
        "epochs = 25\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.keras\"),\n",
        "]\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(3e-4),\n",
        "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.BinaryAccuracy(name=\"acc\")],\n",
        ")\n",
        "model.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=val_ds,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk6x9BBDUvHD"
      },
      "source": [
        "\n",
        "Alcanzamos una precisión de validación superior al 90 % después de entrenar durante 25 épocas con el conjunto de datos completo (en la práctica, se puede entrenar durante más de 50 épocas antes de que el rendimiento de la validación comience a disminuir)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqdvimEPUvHD"
      },
      "source": [
        "\n",
        "## Ejecutar inferencia con datos nuevos\n",
        "\n",
        "debemos tener en cuenta que el aumento y la eliminación de datos están inactivos durante la inferencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgOvG-TrUvHE"
      },
      "outputs": [],
      "source": [
        "img = keras.utils.load_img(\"PetImages/Cat/6779.jpg\", target_size=image_size)\n",
        "plt.imshow(img)\n",
        "\n",
        "img_array = keras.utils.img_to_array(img)\n",
        "img_array = keras.ops.expand_dims(img_array, 0)  # Create batch axis\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = float(keras.ops.sigmoid(predictions[0][0]))\n",
        "print(f\"This image is {100 * (1 - score):.2f}% cat and {100 * score:.2f}% dog.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "image_classification_from_scratch",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}